{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOmkIw/mPT1LLehgD+iR2PG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gAoyOaHaroHm"},"outputs":[],"source":["!mkdir squad\n","!wget https://raw.githubusercontent.com/chiahsuan156/Spoken-SQuAD/master/spoken_train-v1.1.json  -O squad/train-v2.0.json\n","!wget https://raw.githubusercontent.com/chiahsuan156/Spoken-SQuAD/master/spoken_test-v1.1_WER54.json -O squad/test-v2.0.json"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"4OEGpxXUwOJW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"theoretical-confirmation"},"outputs":[],"source":["import os\n","import requests\n","import json\n","from pathlib import Path"]},{"cell_type":"code","source":["import json\n","\n","def read_squad(path):\n","    # open JSON file and load intro dictionary\n","    with open(path, 'rb') as f:\n","        squad_dict = json.load(f)\n","\n","    # initialize lists for contexts, questions, and answers\n","    contexts = []\n","    questions = []\n","    answers = []\n","    # iterate through all data in squad data\n","    for group in squad_dict['data']:\n","        for passage in group['paragraphs']:\n","            context = passage['context']\n","            for qa in passage['qas']:\n","                question = qa['question']\n","                # check if we need to be extracting from 'answers' or 'plausible_answers'\n","                if 'plausible_answers' in qa.keys():\n","                    access = 'plausible_answers'\n","                else:\n","                    access = 'answers'\n","                for answer in qa[access]:\n","                    # append data to lists\n","                    contexts.append(context)\n","                    questions.append(question)\n","                    answers.append(answer)\n","    # return formatted data lists\n","    return contexts, questions, answers"],"metadata":{"id":"4sO4yI63vmuZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_contexts, train_questions, train_answers = read_squad('/content/squad/train-v2.0.json')\n","test_contexts, test_questions, test_answers = read_squad('/content/squad/test-v2.0.json')"],"metadata":{"id":"_IkZE6kiv_Xq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_end_idx(answers, contexts):\n","    # loop through each answer-context pair\n","    for answer, context in zip(answers, contexts):\n","        # gold_text refers to the answer we are expecting to find in context\n","        gold_text = answer['text']\n","        # we already know the start index\n","        start_idx = answer['answer_start']\n","        # and ideally this would be the end index...\n","        end_idx = start_idx + len(gold_text)\n","\n","        # ...however, sometimes squad answers are off by a character or two\n","        if context[start_idx:end_idx] == gold_text:\n","            # if the answer is not off :)\n","            answer['answer_end'] = end_idx\n","        else:\n","            # this means the answer is off by 1-2 tokens\n","            for n in [1, 2]:\n","                if context[start_idx-n:end_idx-n] == gold_text:\n","                    answer['answer_start'] = start_idx - n\n","                    answer['answer_end'] = end_idx - n\n","            \n","# and apply the function to our two answer lists\n","add_end_idx(train_answers, train_contexts)\n","add_end_idx(test_answers, test_contexts)"],"metadata":{"id":"96_03N8VwBit"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DistilBertTokenizerFast\n","# initialize the tokenizer\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","# tokenize\n","train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n","test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)"],"metadata":{"id":"G8wt0AHlwJZt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_token_positions(encodings, answers):\n","    start_positions = []\n","    end_positions = []\n","\n","    for i in range(len(answers)):\n","        # append start token position using char_to_token method\n","        start_position = encodings.char_to_token(i, answers[i]['answer_start'])\n","        start_positions.append(start_position)\n","        \n","        # find end position based on answer text length\n","        answer_length = len(answers[i]['text'])\n","        end_position = encodings.char_to_token(i, max(0, answers[i]['answer_start'] + answer_length - 1))\n","        end_positions.append(end_position)\n","\n","        # if start position is None, the answer passage has been truncated\n","        if start_positions[-1] is None:\n","            start_positions[-1] = tokenizer.model_max_length\n","        \n","        # end position cannot be found, char_to_token found space, so shift position until found\n","        shift = 1\n","        while end_positions[-1] is None:\n","            end_positions[-1] = encodings.char_to_token(i, max(0, answers[i]['answer_start'] + answer_length - 1 - shift))\n","            shift += 1\n","\n","    # update our encodings object with the new token-based start/end positions\n","    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","\n","# apply function to our data\n","add_token_positions(train_encodings, train_answers)\n","add_token_positions(test_encodings, test_answers)\n","\n"],"metadata":{"id":"JSn9ev1ewgV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","class SquadDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","# build datasets for both our training and validation sets\n","train_dataset = SquadDataset(train_encodings)\n","test_dataset = SquadDataset(test_encodings)"],"metadata":{"id":"Xl1bPIiCx_F-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DistilBertForQuestionAnswering\n","model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"],"metadata":{"id":"oXsr7egXy_3E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from transformers import AdamW\n","from tqdm import tqdm\n","\n","# setup GPU/CPU\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# move model over to detected device\n","model.to(device)\n","# activate training mode of model\n","model.train()\n","# initialize adam optimizer with weight decay (reduces chance of overfitting)\n","optim = AdamW(model.parameters(), lr=2e-6)\n","\n","# initialize data loader for training data\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","for epoch in range(4):\n","    # set model to train mode\n","    model.train()\n","    # setup loop (we use tqdm for the progress bar)\n","    loop = tqdm(train_loader, leave=True)\n","    for batch in loop:\n","        # initialize calculated gradients (from prev step)\n","        optim.zero_grad()\n","        # pull all the tensor batches required for training\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        start_positions = batch['start_positions'].to(device)\n","        end_positions = batch['end_positions'].to(device)\n","        # train model on batch and return outputs (incl. loss)\n","        outputs = model(input_ids, attention_mask=attention_mask,\n","                        start_positions=start_positions,\n","                        end_positions=end_positions)\n","        # extract loss\n","        loss = outputs[0]\n","        # calculate loss for every parameter that needs grad update\n","        loss.backward()\n","        # update parameters\n","        optim.step()\n","        # print relevant info to progress bar\n","        loop.set_description(f'Epoch {epoch}')\n","        loop.set_postfix(loss=loss.item())"],"metadata":{"id":"4AFbSYx-zF6r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"y2FFEhsQznCn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = '/content/MyDrive/gmodels/bert_base_uncased-custom'\n","model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)"],"metadata":{"id":"yOnqsgONzuJl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# switch model out of training mode\n","model.eval()\n","\n","#val_sampler = SequentialSampler(val_dataset)\n","val_loader = DataLoader(test_dataset, batch_size=16)\n","\n","acc = []\n","\n","# initialize loop for progress bar\n","loop = tqdm(val_loader)\n","# loop through batches\n","for batch in loop:\n","    # we don't need to calculate gradients as we're not training\n","    with torch.no_grad():\n","        # pull batched items from loader\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        start_true = batch['start_positions'].to(device)\n","        end_true = batch['end_positions'].to(device)\n","        # make predictions\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        # pull preds out\n","        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n","        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n","        # calculate accuracy for both and append to accuracy list\n","        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n","        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n","# calculate average accuracy in total\n","acc = sum(acc)/len(acc)"],"metadata":{"id":"1pCrBdhKz9sI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print (acc)"],"metadata":{"id":"uzW1YwHU7VCT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"T/F\\tstart\\tend\\n\")\n","for i in range(len(start_true)):\n","    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n","          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")"],"metadata":{"id":"Fg7NPHin7dgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# switch model out of training mode\n","model.eval()\n","\n","#val_sampler = SequentialSampler(val_dataset)\n","val_loader = DataLoader(test_dataset, batch_size=16)\n","\n","true_starts = []\n","true_ends = []\n","pred_starts = []\n","pred_ends = []\n","\n","# initialize loop for progress bar\n","loop = tqdm(val_loader)\n","# loop through batches\n","for batch in loop:\n","    # we don't need to calculate gradients as we're not training\n","    with torch.no_grad():\n","        # pull batched items from loader\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        start_true = batch['start_positions'].to(device)\n","        end_true = batch['end_positions'].to(device)\n","        # make predictions\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        # pull preds out\n","        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n","        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n","        # append predictions and true values to lists\n","        true_starts.extend(start_true.cpu().numpy())\n","        true_ends.extend(end_true.cpu().numpy())\n","        pred_starts.extend(start_pred.cpu().numpy())\n","        pred_ends.extend(end_pred.cpu().numpy())\n","import numpy as np\n","# calculate precision and recall\n","true_starts = np.array(true_starts)\n","true_ends = np.array(true_ends)\n","pred_starts = np.array(pred_starts)\n","pred_ends = np.array(pred_ends)\n","\n","true_pos_starts = np.sum(np.logical_and(true_starts == pred_starts, true_starts != -1))\n","true_pos_ends = np.sum(np.logical_and(true_ends == pred_ends, true_ends != -1))\n","false_pos_starts = np.sum(np.logical_and(true_starts != pred_starts, pred_starts != -1))\n","false_pos_ends = np.sum(np.logical_and(true_ends != pred_ends, pred_ends != -1))\n","false_neg_starts = np.sum(np.logical_and(true_starts != pred_starts, true_starts != -1))\n","false_neg_ends = np.sum(np.logical_and(true_ends != pred_ends, true_ends != -1))\n","\n","precision_starts = true_pos_starts / (true_pos_starts + false_pos_starts + 1e-9)\n","recall_starts = true_pos_starts / (true_pos_starts + false_neg_starts + 1e-9)\n","precision_ends = true_pos_ends / (true_pos_ends + false_pos_ends + 1e-9)\n","recall_ends = true_pos_ends / (true_pos_ends + false_neg_ends + 1e-9)\n","\n","# calculate F1 score\n","f1_starts = 2 * (precision_starts * recall_starts) / (precision_starts + recall_starts + 1e-9)\n","f1_ends = 2 * (precision_ends * recall_ends) / (precision_ends + recall_ends + 1e-9)\n","f1 = (f1_starts + f1_ends) / 2\n","\n","print(\"F1 score: {:.4f}\".format(f1))"],"metadata":{"id":"_cNyhH2J74pc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yuQcbn058Pyc"},"execution_count":null,"outputs":[]}]}